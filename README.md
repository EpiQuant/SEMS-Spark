# SEMS-Spark

## Problems that occurred during dev

### Update on May 17th, 2017
While Jacob found a way to use DataFrames to conduct the regressions, one cannot simply use a map function to conduct the regressions spread out over the cluster. He tried to use sparkContext.parallelize(list_of_potential_snps).map(conductRegressions...) to conduct the regressions on the worker nodes, but it looks like it cannot be done so simply. Once things are parallelized with sparkContext, the workers do not appear to be able to find the dataframe passed to the map function.

Jacob is looking more deeply into Spark ml's Pipelines API, as it looks like it may make conducting the regressions in parallel simpler

## Parsing output
Let's make the output of the parsers be in the following format:

(Vector[(String, Vector[Double])], Vector[String]) where the first entry in the tuple is a collection of key-value associations (tuples really, but spark can treat this as a K-V pair) where the key is the SNP name and the Value is a collection of the SNPs values. The second entry is a collection of the Sample names in the same order as the values in the K-V pair.

It may be best to define a case class instead of dealing with these tuples:

case class ParsedInput(orderedSampleNames: Vector[String], snpInfo: Vector[(String, Vector[Double])])

## Notes on LinearRegression
The Class Jacob is using to conduct the regression is simply called org.apache.spark.ml.LinearRegression
https://spark.apache.org/docs/2.0.1/api/java/org/apache/spark/ml/regression/LinearRegression.html

It produces an object of class org.apache.spark.ml.LinearRegressionModel
https://spark.apache.org/docs/2.0.1/api/java/org/apache/spark/ml/regression/LinearRegressionModel.html

# Procedure

Given Phenotype data Y and a set of SNP data {X1, x2, X3, ... XN}

** Step 1 (Perform regressions) **
For each X:
  perform an ordinary least squares linear regression including X and any other Xs that were added to the model previously

** Step 2 (Find the best regression model) **
Of all of the linear regression models produced in Step 1, find the one whose most recently added term has the smallest p-value, and consider that X included in the model if it meets the p-value threshold (Thus ending the "Forward Step" portion of this iteration)

** Step 3 (check for now insignificant terms) **
Inspect the p-values of all of the other terms included in the best regression model found in Step 2. If any of those terms now have p-values that do not meet the threshold, remove them from the model and skip their evaluation on the next iteration of model building (but only for a single iteration: put them back in after the next iteration)

** Return or repeat **
if there are no more Xs under consideration and there was a term that was found to be insignificant in step 3, conduct one last regression with that term removed, and return that model

else if there are no more Xs under consideration and nothing was found to be insignificant, return the best regression model found in Step 2

else if the best regression model returned in Step 2 has a p-value that does not meet the threshold, return the best regression model generated by the previous iteration (unless this is the first iteration, then throw an exception that no Xs meet the threshold)

else: repeat this process with the new included terms
